{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./Desktop/SMSSpamCollection',\n",
    "                    sep='\\t', inferSchema=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0 |_c1                                                                                                                                                        |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam|Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|ham |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|ham |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|status|message                                                                                                                                                    |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham   |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham   |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|ham   |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|ham   |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('_c0', 'status').withColumnRenamed('_c1', 'message')\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the status column to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|1.0  |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|1.0  |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('temp')\n",
    "df = spark.sql(\n",
    "    'select case status when \"ham\" then 1.0  else 0 end as label, message from temp')\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|             message|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(label,DecimalType(11,1),true),StructField(message,StringType,true),StructField(words,ArrayType(StringType,true),true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsData.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(wordsData)\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizedData.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply term frequency-inverse document frequency(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "# We want only the label and features columns for our machine learning models\n",
    "rescaledData.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training(80%) and testing(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0  # set seed for reproducibility\n",
    "trainDF, testDF = rescaledData.randomSplit([0.8, 0.2], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In spark.ml logistic regression can be used to predict a binary outcome by using binominal logistic regression, or it can be used to predict a multiclass outcome by using multinomial logistic regression. Use the family parameter to select between these algorithms, or leave it unset and Spark will infer the correct variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, np.linspace(0.3, 0.01, 10)) \\\n",
    "    .addGrid(lr.elasticNetParam, np.linspace(0.3, 0.8, 6)) \\\n",
    "    .build()\n",
    "crossval_lr = CrossValidator(estimator=lr,\n",
    "                             estimatorParamMaps=paramGrid_lr,\n",
    "                             evaluator=BinaryClassificationEvaluator(),\n",
    "                             numFolds=5)\n",
    "cvModel_lr = crossval_lr.fit(trainDF)\n",
    "best_model_lr = cvModel_lr.bestModel.summary\n",
    "best_model_lr.predictions.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As shown below, we see the data was fitted perfectly. We will see models performance with the test data. We have to practice caution when the models show extraordinary performance with the training data as this can be due to overfitting problem which makes the model not to generalize to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_lr = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_lr = best_model_lr.predictions.select('label', 'prediction')\n",
    "train_fit_lr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using the test data and evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = cvModel_lr.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval_lr.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong(naive) independence assumptions between the features. The spark.ml implementation currently supports both multinominal naive Bayes and Bernoulli naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes()\n",
    "paramGrid_nb = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, np.linspace(0.3, 10, 10)) \\\n",
    "    .build()\n",
    "crossval_nb = CrossValidator(estimator=nb,\n",
    "                             estimatorParamMaps=paramGrid_nb,\n",
    "                             evaluator=BinaryClassificationEvaluator(),\n",
    "                             numFolds=5)\n",
    "cvModel_nb = crossval_nb.fit(trainDF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Shown below are the average area under the curve values for the ten smoothing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel_nb.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb = cvModel_nb.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We see that this model missed some ham messages but it has better performance in identifying spam message than the logistic regression we built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Extreme Gradient Boosting supports various objective functions, including regression, classification, and ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_plant = pd.read_excel('/home/ian/Downloads/CCPP/Folds5x2_pp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_plant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test datasets\n",
    "X = power_plant.drop('PE', axis=1)\n",
    "y = power_plant['PE'].values\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the training and testing sets into DMatrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_train = xgb.DMatrix(data=X_train,\n",
    "                       label=y_train)\n",
    "DM_test = xgb.DMatrix(data=X_test,\n",
    "                      label=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are different hyperparameters that we can tune and the parametres are different from baselearner to baselearner. In tree based learners, which are the most common ones in xgboost applications, the following are the most commonly tuned hyperparameters:\n",
    "learning rate:\n",
    "\n",
    "    1.learning rate/eta- governs how quickly the model fits the         residual error using additional base learners. If it is a smaller learning rate, it will need more boosting rounds, hence more time, to achieve the same reduction in residual error as one with larger learning rate. Typically, it lies between 0.01 – 0.3\n",
    "    The three hyperparameters below are regularization hyperparameters.\n",
    "    2.gamma: min loss reduction to create new tree split. default = 0 means no regularization.\n",
    "    3.lambda: L2 reg on leaf weights. Equivalent to Ridge regression.\n",
    "    4.alpha: L1 reg on leaf weights. Equivalent to Lasso regression.\n",
    "    5.max_depth: max depth per tree. This controls how deep our tree can grow. The Larger the depth, more complex the model will be and higher chances of overfitting. Larger data sets require deep trees to learn the rules from data. Default = 6.\n",
    "    6.subsample: % samples used per tree. This is the fraction of the total training set that can be used in any boosting round. Low value may lead to underfitting issues. A very high value can cause over-fitting problems.\n",
    "    7.colsample_bytree: % features used per tree. This is the fraction of the number of columns that we can use in any boosting round. A smaller value is an additional regularization and a larger value may be cause overfitting issues.\n",
    "    8.n_estimators: number of estimators (base learners). This is the number of boosting rounds.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In both R and Python, the default base learners are trees (gbtree) but we can also specify gblinear for linear models and dart for both classification and regression problems.\n",
    "In this post, I will optimize only three of the parameters shown above and you can try optimizing the other parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {\n",
    "    'colsample_bytree': np.linspace(0.5, 0.9, 5),\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20, 25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform 5 fold cross-validation using mean square error as a scoring method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid,\n",
    "                        scoring='neg_mean_squared_error', cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit grid_mse to the data, get best parameters and best score (lowest RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mse.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_mse.predict(X_test)\n",
    "print(\"Root mean square error for test dataset: {}\".format(\n",
    "    np.round(np.sqrt(mean_squared_error(y_test, pred)), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"prediction\": pred, \"observed\": y_test.flatten()})\n",
    "lowess = sm.nonparametric.lowess\n",
    "z = lowess(pred.flatten(), y_test.flatten())\n",
    "test.plot(figsize=[14, 8],\n",
    "          x=\"prediction\", y=\"observed\", kind=\"scatter\", color='darkred')\n",
    "plt.title(\"Extreme Gradient Boosting: Prediction Vs Test Data\",\n",
    "          fontsize=18, color=\"darkgreen\")\n",
    "plt.xlabel(\"Predicted Power Output\", fontsize=18)\n",
    "plt.ylabel(\"Observed Power Output\", fontsize=18)\n",
    "plt.plot(z[:, 0], z[:, 1], color=\"blue\", lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
