{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./Desktop/123/df.csv',\n",
    "                    sep='\\t', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('label','url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'url']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[label: int, url: string]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "| null|      2|\n",
      "|    1| 552302|\n",
      "|    0|1879621|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1| 552302|\n",
      "|    0|1879621|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|label|url           |\n",
      "+-----+--------------+\n",
      "|1    |www.kaola.com |\n",
      "|1    |www.kaola.com |\n",
      "|1    |www.acgjie.com|\n",
      "|0    |www.ifanr.com |\n",
      "|1    |bbs.55bbs.com |\n",
      "+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('label',regexp_extract('url',\"//(.*?)/\",1).alias('url'))\n",
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|url           |label|\n",
      "+--------------+-----+\n",
      "|www.kaola.com |1.0  |\n",
      "|www.kaola.com |1.0  |\n",
      "|www.acgjie.com|1.0  |\n",
      "|www.ifanr.com |0.0  |\n",
      "|bbs.55bbs.com |1.0  |\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('url',df.label.cast(\"float\").alias('label'))\n",
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------------+\n",
      "|url           |label|split             |\n",
      "+--------------+-----+------------------+\n",
      "|www.kaola.com |1.0  |[www, kaola, com] |\n",
      "|www.kaola.com |1.0  |[www, kaola, com] |\n",
      "|www.acgjie.com|1.0  |[www, acgjie, com]|\n",
      "|www.ifanr.com |0.0  |[www, ifanr, com] |\n",
      "|bbs.55bbs.com |1.0  |[bbs, 55bbs, com] |\n",
      "+--------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer =RegexTokenizer(inputCol='url',outputCol='split',pattern='\\\\W')\n",
    "splitdf = tokenizer.transform(df)\n",
    "splitdf.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "#remover = StopWordsRemover(inputCol='split', outputCol='filtered',stopWords=['com','cn'])\n",
    "#filterdf = remover.transform(splitdf)\n",
    "#filterdf.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|url|label|split|\n",
      "+---+-----+-----+\n",
      "|   |  0.0|   []|\n",
      "|   |  0.0|   []|\n",
      "|   |  0.0|   []|\n",
      "|   |  0.0|   []|\n",
      "|   |  1.0|   []|\n",
      "|   |  0.0|   []|\n",
      "|   |  1.0|   []|\n",
      "|   |  1.0|   []|\n",
      "|   |  1.0|   []|\n",
      "|   |  0.0|   []|\n",
      "+---+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitdf.filter(' url not like \"%.%\" ').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdf = splitdf.filter(' url != \"\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------------+\n",
      "|           url|label|             split|\n",
      "+--------------+-----+------------------+\n",
      "| www.kaola.com|  1.0| [www, kaola, com]|\n",
      "| www.kaola.com|  1.0| [www, kaola, com]|\n",
      "|www.acgjie.com|  1.0|[www, acgjie, com]|\n",
      "| www.ifanr.com|  0.0| [www, ifanr, com]|\n",
      "| bbs.55bbs.com|  1.0| [bbs, 55bbs, com]|\n",
      "+--------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------------+----------------------------------+\n",
      "|url           |label|split             |rawFeatures                       |\n",
      "+--------------+-----+------------------+----------------------------------+\n",
      "|www.kaola.com |1.0  |[www, kaola, com] |(262144,[0,3,24],[1.0,1.0,1.0])   |\n",
      "|www.kaola.com |1.0  |[www, kaola, com] |(262144,[0,3,24],[1.0,1.0,1.0])   |\n",
      "|www.acgjie.com|1.0  |[www, acgjie, com]|(262144,[0,3,13263],[1.0,1.0,1.0])|\n",
      "|www.ifanr.com |0.0  |[www, ifanr, com] |(262144,[0,3,525],[1.0,1.0,1.0])  |\n",
      "|bbs.55bbs.com |1.0  |[bbs, 55bbs, com] |(262144,[0,58,87],[1.0,1.0,1.0])  |\n",
      "+--------------+-----+------------------+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(inputCol='split', outputCol=\"rawFeatures\")\n",
    "model = count.fit(splitdf)\n",
    "featuredf = model.transform(splitdf)\n",
    "featuredf.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featuredf.na.drop(how=\"all\").show(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featuredf)\n",
    "finaldf = idfModel.transform(featuredf)\n",
    "# We want only the label and features columns for our machine learning models\n",
    "fdf = finaldf.select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(262144,[0,3,24],...|\n",
      "|  1.0|(262144,[0,3,24],...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0  # set seed for reproducibility\n",
    "trainDF, testDF = fdf.randomSplit([0.8, 0.2], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934062, 482583)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count(),testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'features', 'rawPrediction', 'probability', 'prediction']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, np.linspace(0.3, 0.01, 10)) \\\n",
    "    .addGrid(lr.elasticNetParam, np.linspace(0.3, 0.8, 6)) \\\n",
    "    .build()\n",
    "crossval_lr = CrossValidator(estimator=lr,\n",
    "                             estimatorParamMaps=paramGrid_lr,\n",
    "                             evaluator=BinaryClassificationEvaluator(),\n",
    "                             numFolds=5)\n",
    "cvModel_lr = crossval_lr.fit(trainDF)\n",
    "best_model_lr = cvModel_lr.bestModel.summary\n",
    "best_model_lr.predictions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area under the curve for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6901801693452801"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_lr = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8239634852679478"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446575135647151"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------+\n",
      "|label|prediction|  count|\n",
      "+-----+----------+-------+\n",
      "|  1.0|       1.0| 178855|\n",
      "|  0.0|       1.0|  39932|\n",
      "|  1.0|       0.0| 260510|\n",
      "|  0.0|       0.0|1454765|\n",
      "+-----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fit_lr = best_model_lr.predictions.select('label', 'prediction')\n",
    "train_fit_lr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446575135647151"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(178855+1454765)/(178855+39932+260510+1454765)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using the test data and evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'features', 'rawPrediction', 'probability', 'prediction']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr = cvModel_lr.transform(testDF)\n",
    "predictions_lr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(262144,[0],[0.22...|[1.73724937097366...|[0.85033734734920...|       0.0|\n",
      "|  0.0|(262144,[0],[0.22...|[1.73724937097366...|[0.85033734734920...|       0.0|\n",
      "|  0.0|(262144,[0],[0.22...|[1.73724937097366...|[0.85033734734920...|       0.0|\n",
      "|  0.0|(262144,[0],[0.22...|[1.73724937097366...|[0.85033734734920...|       0.0|\n",
      "|  0.0|(262144,[0],[0.22...|[1.73724937097366...|[0.85033734734920...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|  1.0|       0.0| 65010|\n",
      "|  0.0|       0.0|362879|\n",
      "|  1.0|       1.0| 44651|\n",
      "|  0.0|       1.0| 10043|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444764941989253"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(362879+44651)/(65010+362879+44651+10043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444764941989253"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.write.csv(\"./Desktop/123.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
